<html>
<head>
  <title>Evernote Export</title>
  <basefont face="微软雅黑 Light" size="2" />
  <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
  <meta name="exporter-version" content="YXBJ Windows/605766 (zh-CN, DDL); Windows/10.0.0 (Win64); EDAMVersion=V2;"/>
  <style>
    body, td {
      font-family: 微软雅黑 Light;
      font-size: 14pt;
    }
  </style>
</head>
<body>
<a name="6561"/>
<h1>赛题介绍</h1>
<div>
<table bgcolor="#D4DDE5" border="0">
<tr><td><b>创建时间：</b></td><td><i>2020/4/9 13:48</i></td></tr>
<tr><td><b>更新时间：</b></td><td><i>2022/11/1 14:59</i></td></tr>
<tr><td><b>作者：</b></td><td><i>不理不理</i></td></tr>
</table>
</div>
<br/>

<div>
<span><div><div><br/></div><div><span style="font-size: 24px;"><a href="https://www.kaggle.com/c/jigsaw-multilingual-toxic-comment-classification">赛题介绍</a></span></div><div><span style="font-size: 14pt;">        该比赛目的是训练一个分类器，使用该分类器自动判断维基百科的评论是否为toxic。</span></div><div><span style="font-size: 14pt; font-weight: bold;">        toxicity</span> <span style="font-size: 14pt;">is defined as anything</span> <span style="font-size: 14pt; font-weight: bold;">rude</span><span style="font-size: 14pt;">,</span> <span style="font-size: 14pt; font-weight: bold;">disrespectful</span> <span style="font-size: 14pt;">or otherwise likely to</span> <span style="font-size: 14pt; font-weight: bold;">make someone leave a discussion.</span></div><div>        值得注意的是，训练和验证的语料只有三种语言，而预测的语料却是六种语言。</div><div><br/></div><div><br/></div><div><br/></div><div style="text-align: left;"><span style="font-size: 18pt; font-weight: bold;">数据集</span></div><div style="text-align: left; margin-left: 40px;"><a href="https://www.kaggle.com/c/jigsaw-multilingual-toxic-comment-classification/data?select=jigsaw-unintended-bias-train.csv">https://www.kaggle.com/c/jigsaw-multilingual-toxic-comment-classification/data?select=jigsaw-unintended-bias-train.csv</a></div><div><br/></div><div><br/></div><div><br/></div><div><span style="font-size: 18pt; font-weight: bold;">评估指标</span></div><div>        Submissions are evaluated on <a href="http://en.wikipedia.org/wiki/Receiver_operating_characteristic">area under the ROC curve</a> between the predicted probability and the observed target.</div><div><br/></div><div><br/></div><div><br/></div><div><span style="font-size: 24px;"><span style="font-size: 24px; font-weight: bold;">数据集分布</span></span></div><div><div><br/></div><table style="border-collapse: collapse; min-width: 100%;"><colgroup><col style="width: 130px;"></col><col style="width: 130px;"></col><col style="width: 130px;"></col><col style="width: 130px;"></col><col style="width: 377px;"></col><col style="width: 154px;"></col></colgroup><tbody><tr><td style="width: 130px; padding: 8px; border: 1px solid;"><div style="text-align: center;"><br/></div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div style="text-align: center;">数据量</div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div style="text-align: center;">正例率</div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div style="text-align: center;">正样本数量</div></td><td style="width: 377px; padding: 8px; border: 1px solid;"><div style="text-align: center;">负样本数量</div></td><td style="width: 154px; padding: 8px; border: 1px solid;"><div style="text-align: center;">语种</div></td></tr><tr><td style="width: 130px; padding: 8px; border: 1px solid;"><div style="text-align: center;">train1</div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div style="text-align: center;">223549</div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div style="text-align: center;">9.57%</div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div style="text-align: center;">21384</div></td><td style="width: 377px; padding: 8px; border: 1px solid;"><div style="text-align: center;">202165</div></td><td style="width: 154px; padding: 8px; border: 1px solid;"><div style="text-align: center;">98.7%英语</div></td></tr><tr><td style="width: 130px; padding: 8px; border: 1px solid;"><div style="text-align: center;">train2</div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div style="text-align: center;">1902194</div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div style="text-align: center;">8%</div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div style="text-align: center;">152111</div></td><td style="width: 377px; padding: 8px; border: 1px solid;"><div style="text-align: center;">1334581（[0, 0.1)）/ 1750083（[0, 0.5)）</div></td><td style="width: 154px; padding: 8px; border: 1px solid;"><div style="text-align: center;"><br/></div></td></tr><tr><td style="width: 130px; padding: 8px; border: 1px solid;"><div style="text-align: center;">valid</div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div style="text-align: center;">8000</div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div style="text-align: center;">15.38%</div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div style="text-align: center;">1230</div></td><td style="width: 377px; padding: 8px; border: 1px solid;"><div style="text-align: center;">6770</div></td><td style="width: 154px; padding: 8px; border: 1px solid;"><div style="text-align: center;">3种语言</div></td></tr><tr><td style="width: 130px; padding: 8px; border: 1px solid;"><div style="text-align: center;">test</div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div style="text-align: center;">63812</div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div style="text-align: center;"><br/></div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div style="text-align: center;"><br/></div></td><td style="width: 377px; padding: 8px; border: 1px solid;"><div style="text-align: center;"><br/></div></td><td style="width: 154px; padding: 8px; border: 1px solid;"><div style="text-align: center;">6种语言</div></td></tr></tbody></table><div>        按照（[0, 0.1)+[0.5, 1]），train1+train2 正例率36.47%，数据量475660。</div></div><div>        train1/valid/test没有重复项，而且valid与test的样本没有交集，即样本没有泄露。但train2的comment_text列有重复项，且重复项对应的标签有时候不一致。</div><div>        train1/train2/valid/test都没有缺失值。</div><div>        xhulu的train2正样本选了112163个左右。</div><div><br/></div><div>        train1的六种语言翻译版本，样本数量：</div><div style="margin-left: 80px;">es 西班牙语 223378</div><div style="margin-left: 80px;">tr 土耳其语 223394</div><div style="margin-left: 80px;">it  意大利语 223394</div><div style="margin-left: 80px;">ru 俄语 223147</div><div style="margin-left: 80px;">pt 葡萄牙语 223394</div><div style="margin-left: 80px;">fr 法语 223394</div><div><br/></div><div><br/></div><div><br/></div><div><span style="font-size: 18pt; font-weight: bold;">train1（</span><span style="font-size: 18pt;"><span style="font-size: 18pt; font-weight: bold;">English comments from Wikipedia’s talk page edits</span></span><span style="font-size: 18pt; font-weight: bold;">）</span></div><ul><ul><li><div>comment_text</div></li><li><div>toxic</div></li></ul></ul><div><br/></div><div><span style="font-weight: bold;">    several additional toxicity subtype attributes：</span></div><ul><ul><li><div>severe_toxic</div></li><li><div>obscene</div></li><li><div>threat</div></li><li><div>insult</div></li><li><div>indentity_hate</div></li></ul></ul><div><br/></div><div>        In this competition, you’re challenged to build a multi-headed model that’s capable of detecting different types of of toxicity like threats, obscenity, insults, and identity-based hate better than Perspective’s <a href="https://github.com/conversationai/unintended-ml-bias-analysis">current models</a>.</div><div><br/></div><div>        train1来源于第一次比赛，第一次比赛的train包含159571条样本，test包含153164条样本，所以train1应该是融合了第一次train+test，然后取的子集。</div><div><br/></div><div><br/></div><div><br/></div><div><span style="font-size: 18pt; font-weight: bold;">train2（</span><span style="font-size: 18pt;"><span style="font-size: 18pt; font-weight: bold;">an expanded version of the Civil Comments dataset with a range of additional labels</span></span><span style="font-size: 18pt; font-weight: bold;">）</span></div><ul><ul><li><div>comment_text</div></li><li><div>toxic</div></li></ul></ul><div><br/></div><div><span style="font-weight: bold;">    several additional toxicity subtype attributes：</span></div><ul><ul><li><div>severe_toxicity</div></li><li><div>obscene</div></li><li><div>threat</div></li><li><div>insult</div></li><li><div>identity_attack</div></li><li><div>sexual_explicit</div></li></ul></ul><div><br/></div><div><span style="font-weight: bold;">    a subset of comments have been labelled with a variety of identity attributes, representing the identities that are mentioned in the comment：</span></div><ul><ul><li><div>male</div></li><li><div>female</div></li><li><div>transgender</div></li><li><div>other_gender</div></li><li><div>heterosexual</div></li><li><div>homosexual_gay_or_lesbian</div></li><li><div>bisexual</div></li><li><div>other_sexual_orientation</div></li><li><div>christian</div></li><li><div>jewish</div></li><li><div>muslim</div></li><li><div>hindu</div></li><li><div>buddhist</div></li><li><div>atheist</div></li><li><div>other_religion</div></li><li><div>black</div></li><li><div>white</div></li><li><div>asian</div></li><li><div>latino</div></li><li><div>other_race_or_ethnicity</div></li><li><div>physical_disability</div></li><li><div>intellectual_or_learning_disability</div></li><li><div>psychiatric_or_mental_illness</div></li><li><div>other_disability</div></li></ul></ul><div><br/></div><div><span style="font-weight: bold;">    metadata from Jigsaw's annotation：</span></div><ul><ul><li><div>toxicity_annotator_count</div></li><li><div>identity_annotator_count</div></li></ul></ul><div><br/></div><div><span style="font-weight: bold;">    metadata from Civil Comments：</span></div><ul><ul><li><div>created_date</div></li><li><div>publication_id</div></li><li><div>parent_id</div></li><li><div>article_id</div></li><li><div>rating</div></li><li><div>funny</div></li><li><div>wow</div></li><li><div>sad</div></li><li><div>likes</div></li><li><div>disagree</div></li></ul></ul><div><br/></div><div>        When the Conversation AI team first built toxicity models, they found that the models <a href="https://medium.com/the-false-positive/unintended-bias-and-names-of-frequently-targeted-groups-8e0b81f80a23">incorrectly learned to associate</a> the names of frequently attacked identities with toxicity. Models predicted a high likelihood of toxicity for comments containing those identities (e.g. &quot;gay&quot;), even when those comments were not actually toxic (such as &quot;I am a gay woman&quot;). This happens because training data was pulled from available sources where unfortunately, certain identities are overwhelmingly referred to in offensive ways. Training a model from data with these imbalances risks simply mirroring those biases back to users.</div><div>        </div><div>        <span style="background-color: rgb(255, 250, 165);-evernote-highlight:true;">In this competition, you're challenged to build a model that recognizes toxicity and minimizes this type of unintended bias with respect to mentions of identities.</span></div><div><span style="background-color: rgb(255, 250, 165);-evernote-highlight:true;"><br/></span></div><div>        train2来源于第二次比赛。</div><div><br/></div><div><br/></div><div><br/></div><div><span style="font-size: 18pt; font-weight: bold;">valid（</span><span style="font-size: 18pt;"><span style="font-size: 18pt; font-weight: bold;">comments from Wikipedia talk pages in different non-English languages</span></span><span style="font-size: 18pt; font-weight: bold;">）</span></div><ul><li><div>comment_text</div></li><li><div>lang</div></li><li><div>toxic</div></li></ul><div><br/></div><div>        语种</div><ul><ul><li><div>tr  3000</div></li><li><div>it   2500</div></li><li><div>es  2500</div></li></ul></ul><div><br/></div><div><br/></div><div><br/></div><div><span style="font-size: 18pt; font-weight: bold;">test（</span><span style="font-size: 18pt;"><span style="font-size: 18pt; font-weight: bold;">comments from Wikipedia talk pages in different non-English languages</span></span><span style="font-size: 18pt; font-weight: bold;">）</span></div><ul><li><div>content</div></li><li><div>lang</div></li></ul><div><br/></div><div>        语种</div><ul><ul><li><div>tr  14000</div></li><li><div>pt 11012</div></li><li><div>ru 10948</div></li><li><div>fr  10920</div></li><li><div>it   8494</div></li><li><div>es 8438</div></li></ul></ul><div style="text-align: center;"><img src="赛题介绍_files/inbox_2280345_bf8ed2c23e24a6d0431e68478fc4ab46_Capture.png" type="image/png" data-filename="inbox_2280345_bf8ed2c23e24a6d0431e68478fc4ab46_Capture.png" width="547"/></div></div><div style="text-align: left;"><br/></div></span>
</div></body></html> 